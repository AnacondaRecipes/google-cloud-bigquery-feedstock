{% set name = "google-cloud-bigquery" %}
{% set version = "3.31.0" %}

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name.replace('-', '_')}}-{{ version }}.tar.gz
  sha256: b89dc716dbe4abdb7a4f873f7050100287bc98514e0614c5d54cd6a8e9fb0991

build:
  number: 0

requirements:
  host:
    - python
    - pip
    - setuptools
    - wheel
  run:
    - python

outputs:
  - name: {{ name }}-core
    build:
      skip: true  # [py<39]
      script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation -vv

    requirements:
      host:
        - python
        - pip
        - setuptools
        - wheel
      run:
        - python
        - google-api-core-grpc >=2.11.1,<3.0.0
        - google-auth >=2.14.1,<3.0.0
        - google-cloud-core >=2.4.1,<3.0.0
        - google-resumable-media >=2.0.0,<3.0
        - packaging >=24.2.0
        - python-dateutil >=2.8.2,<3.0
        - requests >=2.21.0,<3.0.0
    test:
      imports:
        - google.api_core
        - google.cloud.bigquery
        - google.cloud.bigquery.client
        - google.cloud.bigquery.dataset
        - google.cloud.bigquery.encryption_configuration
        - google.cloud.bigquery.enums
        - google.cloud.bigquery.external_config
        - google.cloud.bigquery.job
        - google.cloud.bigquery.model
        - google.cloud.bigquery.query
        - google.cloud.bigquery.retry
        - google.cloud.bigquery.routine
        - google.cloud.bigquery.schema
        - google.cloud.bigquery.table
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}
    build:
      skip: true  # [py<39]
    requirements:
      host:
        - python
        - pip
        - setuptools
        - wheel
      run:
        - python
        - {{ pin_subpackage('google-cloud-bigquery-core', exact=True) }}
        - google-cloud-bigquery-storage >=2.18.0,<3.0.0
        - grpcio >=1.47.0,<2.0.0  # [py<311]
        - grpcio >=1.49.1,<2.0.0  # [py>=311]
        - pyarrow >=4.0.0
      run_constrained:
        - pandas >=1.1.4
        - pandas-gbq >= 0.26.1
        - db-dtypes >=1.0.4,<2.0.0
        - ipywidgets >=7.7.1
        - ipykernel >=6.2.0
        - geopandas >=0.9.0,<2.0
        - shapely >=1.8.4,<3.0.0
        - ipython >=7.23.1
        - bigquery-magics >=0.6.0
        - tqdm >=4.7.4,<=5.0.0
        - opentelemetry-api >=1.1.0
        - opentelemetry-sdk >=1.1.0
        - opentelemetry-instrumentation >=0.20b0
        - proto-plus >=1.22.3,<2.0.0
        - protobuf >=3.20.2,<7.0.0,!=4.21.0-4.21.5
    test:
      source_files:
        - tests/unit
        - tests/__init__.py
      imports:
        - google.api_core
        - google.cloud.bigquery
        - google.cloud.bigquery.client
        - google.cloud.bigquery.dataset
        - google.cloud.bigquery.encryption_configuration
        - google.cloud.bigquery.enums
        - google.cloud.bigquery.external_config
        - google.cloud.bigquery.job
        - google.cloud.bigquery.magics
        - google.cloud.bigquery.model
        - google.cloud.bigquery.query
        - google.cloud.bigquery.retry
        - google.cloud.bigquery.routine
        - google.cloud.bigquery.schema
        - google.cloud.bigquery.table
        - google.cloud.bigquery_v2
        - google.cloud.bigquery_v2.types
      commands:
        - pip check
        # ignore test_magics.py, test_table.py, and test_client.py
        # because they use test_utils, unavailable
        # https://github.com/googleapis/python-bigquery/issues/1758
        - pytest -vv tests/unit --ignore=tests/unit/test_magics.py --ignore=tests/unit/test_table.py --ignore=tests/unit/test_client.py
      requires:
        - pip
        - pytest
        - freezegun
        - ipython >=7.23.1
        - db-dtypes >=1.0.4,<2.0.0

about:
  home: https://github.com/googleapis/python-bigquery
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: BigQuery API client library
  description: |
    Querying massive datasets can be time consuming and expensive without
    the right hardware and infrastructure. Google BigQuery solves this problem
    by enabling super-fast, SQL queries against append-mostly tables, using
    the processing power of Google's infrastructure.
  doc_url: https://googleapis.dev/python/bigquery/latest
  dev_url: https://github.com/googleapis/python-bigquery

extra:
  recipe-maintainers:
    - chalmerlowe
    - xylar
    - parthea
    - tswast
  skip-lints:
    - wrong_output_script_key
